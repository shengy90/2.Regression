{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "30th July - Optimal Clusters",
      "provenance": [],
      "collapsed_sections": [
        "svsqrk45tb_B",
        "G4sbx8kLH89t",
        "uICiUW0YyfAZ",
        "Us6xVpclRb_A",
        "Ly1lLTEs0yxu",
        "unpMyGpN01AE",
        "hwTqc9CP_DWF",
        "Kky74E1-V67I"
      ],
      "toc_visible": true,
      "mount_file_id": "1XQiLyjIhVdgtFhuzVLHo5QTOzMLa85lV",
      "authorship_tag": "ABX9TyPTSz4QUlQDOK2Bv4kEzdK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengy90/2.Regression/blob/Week1/notebooks/30th_July_Optimal_Clusters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svsqrk45tb_B",
        "colab_type": "text"
      },
      "source": [
        "# **1Ô∏è‚É£ Setup Notebook üíª**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eJpHGVpGuji",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Authenticate with BigQuery ‚òÅÔ∏è**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkaOt64QmU90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade google-cloud-bigquery[bqstorage,pandas]\n",
        "!pip install --upgrade pandas-gbq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6y1_cKZGJ1C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8f4aac7-4820-465e-fbcf-2cbc91d04308"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Authenticated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cPJ-kLQGQ0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df --use_bqstorage_api\n",
        "SELECT \n",
        "  COUNT(*) as total_rows\n",
        "FROM `machine-learning-msc.low_carbon_london.household_consumption_daily_agg` "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts6qMG3PGlUL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "6a22653e-08e0-4eac-a6d2-1dbdc7208169"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>total_rows</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14841792</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   total_rows\n",
              "0    14841792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4sbx8kLH89t",
        "colab_type": "text"
      },
      "source": [
        "### **Importing Libraries‚è¨**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmVtQy38Ozr6",
        "colab_type": "text"
      },
      "source": [
        "##### Standard Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0JiDvCG3U4F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "c8d4eec7-891a-4588-92a9-063fadf937a9"
      },
      "source": [
        "!pip install fbprophet\n",
        "!pip install MiniSom"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fbprophet in /usr/local/lib/python3.6/dist-packages (0.6)\n",
            "Requirement already satisfied: Cython>=0.22 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.29.21)\n",
            "Requirement already satisfied: cmdstanpy==0.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.4.0)\n",
            "Requirement already satisfied: pystan>=2.14 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.19.1.1)\n",
            "Requirement already satisfied: numpy>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.0.5)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (3.2.2)\n",
            "Requirement already satisfied: LunarCalendar>=0.0.9 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.0.9)\n",
            "Requirement already satisfied: convertdate>=2.1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.2.1)\n",
            "Requirement already satisfied: holidays>=0.9.5 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (0.9.12)\n",
            "Requirement already satisfied: setuptools-git>=1.2 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from fbprophet) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->fbprophet) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->fbprophet) (1.2.0)\n",
            "Requirement already satisfied: ephem>=3.7.5.3 in /usr/local/lib/python3.6/dist-packages (from LunarCalendar>=0.0.9->fbprophet) (3.7.7.1)\n",
            "Requirement already satisfied: pymeeus<=1,>=0.3.6 in /usr/local/lib/python3.6/dist-packages (from convertdate>=2.1.2->fbprophet) (0.3.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from holidays>=0.9.5->fbprophet) (1.15.0)\n",
            "Requirement already satisfied: MiniSom in /usr/local/lib/python3.6/dist-packages (2.2.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr9vUfxAICRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "95e0b050-944f-41cc-d647-c5c281118d46"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import random\n",
        "import datetime as dt\n",
        "\n",
        "from minisom import MiniSom\n",
        "from tqdm import tqdm\n",
        "from datetime import date\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        " \n",
        "sns.set()\n",
        "%matplotlib inline"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQE0xrL4JT4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas_gbq\n",
        "def output_to_bq(forecast, table_id, project_id='machine-learning-msc'):\n",
        "    pandas_gbq.to_gbq(forecast, table_id, project_id=project_id, if_exists='append')"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq2GQCXqO2ZD",
        "colab_type": "text"
      },
      "source": [
        "##### Import Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw_bhwfTY7U1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a5972957-2b6f-4a2b-c62d-8407bcc0c025"
      },
      "source": [
        "%cd /content\n",
        "!ls"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "adc.json  mscproj  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtzIWQvBPESj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a3b75ac4-091d-43af-9b8f-ecf3f7df05b4"
      },
      "source": [
        "!rm -rf mscproj\n",
        "!git clone https://github.com/shengy90/MSc-Project mscproj\n",
        "!git pull\n",
        "%cd /content/mscproj/\n",
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'mscproj'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 377 (delta 5), reused 8 (delta 4), pack-reused 361\u001b[K\n",
            "Receiving objects: 100% (377/377), 10.94 MiB | 26.06 MiB/s, done.\n",
            "Resolving deltas: 100% (203/203), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "/content/mscproj\n",
            "bin\t     __init__.py  notebooks  requirements.txt  sql\n",
            "definitions  Makefile\t  README.md  run.py\t       src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnq6lOTUXbat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload \n",
        "%autoreload 2 \n",
        "from src.train_prophet import TrainProphet\n",
        "from src.train_clusters import TrainClusters\n",
        "from src.train_clusters import Normaliser"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uICiUW0YyfAZ",
        "colab_type": "text"
      },
      "source": [
        "# 2Ô∏è‚É£ **Generate SOM clusters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us6xVpclRb_A",
        "colab_type": "text"
      },
      "source": [
        "### **Downloading Data from BQ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VfmGhaSz4s4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_test --use_bqstorage_api\n",
        "WITH stg1 AS (\n",
        "SELECT \n",
        "lcl_id,\n",
        "IF(acorn_grouped = \"Adversity\", 1, 0) AS adversity,\n",
        "IF(acorn_grouped = \"Affluent\", 1, 0) AS affluent,\n",
        "IF(acorn_grouped = \"Comfortable\", 1, 0) AS comfortable,\n",
        "FORMAT_DATETIME(\"%B\", DATETIME(ts)) AS month_name,\n",
        "dayofweek,\n",
        "hhourly_rank,\n",
        "ROUND(AVG(kwhh),4) AS hh_avg,\n",
        "ROUND(MAX(kwhh),4) AS hh_max,\n",
        "ROUND(MIN(kwhh),4) AS hh_min,\n",
        "ROUND(STDDEV(kwhh),4) AS hh_stddev\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.test_set`\n",
        "WHERE train_test_split = 'test'\n",
        "AND ts >= '2012-11-01' AND ts < '2013-03-01'\n",
        "\n",
        "GROUP BY 1,2,3,4,5,6,7\n",
        ")\n",
        "\n",
        "SELECT \n",
        "*,\n",
        "ROW_NUMBER() OVER (PARTITION BY lcl_id, month_name ORDER BY dayofweek ASC, hhourly_rank ASC) AS weekly_rank\n",
        "FROM stg1 \n",
        "ORDER BY lcl_id, month_name, weekly_rank, hhourly_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAKqRE4AIKRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_train --use_bqstorage_api\n",
        "WITH stg1 AS (\n",
        "SELECT \n",
        "lcl_id,\n",
        "IF(acorn_grouped = \"Adversity\", 1, 0) AS adversity,\n",
        "IF(acorn_grouped = \"Affluent\", 1, 0) AS affluent,\n",
        "IF(acorn_grouped = \"Comfortable\", 1, 0) AS comfortable,\n",
        "FORMAT_DATETIME(\"%B\", DATETIME(ts)) AS month_name,\n",
        "dayofweek,\n",
        "hhourly_rank,\n",
        "ROUND(AVG(kwhh),4) AS hh_avg,\n",
        "ROUND(MAX(kwhh),4) AS hh_max,\n",
        "ROUND(MIN(kwhh),4) AS hh_min,\n",
        "ROUND(STDDEV(kwhh),4) AS hh_stddev\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.train_set`\n",
        "WHERE train_test_split = 'train'\n",
        "AND ts >= '2012-11-01' AND ts < '2013-03-01'\n",
        "\n",
        "GROUP BY 1,2,3,4,5,6,7\n",
        ")\n",
        "\n",
        "SELECT \n",
        "*,\n",
        "ROW_NUMBER() OVER (PARTITION BY lcl_id, month_name ORDER BY dayofweek ASC, hhourly_rank ASC) AS weekly_rank\n",
        "FROM stg1 \n",
        "ORDER BY lcl_id, month_name, weekly_rank, hhourly_rank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly1lLTEs0yxu",
        "colab_type": "text"
      },
      "source": [
        "### **Normalise Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNhVyPMcyjAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "value_list = ['hh_avg']\n",
        "column_list = ['month_name', 'weekly_rank']\n",
        "normaliser = Normaliser(value_list, column_list)\n",
        "norm_df_train = normaliser.fit(df_train)\n",
        "norm_df_test = normaliser.predict(df_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unpMyGpN01AE",
        "colab_type": "text"
      },
      "source": [
        "### **Train SOM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUaW1PJi0wfE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e99ed3a0-d720-4c4e-afd1-41c02378a080"
      },
      "source": [
        "for i in range(9):\n",
        "    cluster_num = i+1\n",
        "    print(f\"Training {cluster_num} clusters....\")\n",
        "    som_cluster = TrainClusters(cluster_type=\"som\")\n",
        "    som_cluster.fit(norm_df_train, cluster_num=cluster_num, sigma=0.1, learning_rate=0.1)  \n",
        "\n",
        "    train_pred = som_cluster.predict(norm_df_train)\n",
        "    test_pred = som_cluster.predict(norm_df_test)\n",
        "\n",
        "    train_pred['train_test_split'] = \"train\"\n",
        "    test_pred['train_test_split'] = \"test\"\n",
        "\n",
        "    som_results = pd.concat([train_pred[['lcl_id','cluster','train_test_split']], test_pred[['lcl_id','cluster','train_test_split']]])\n",
        "    som_results['num_clusters'] = cluster_num\n",
        "    som_results['cluster_type'] = 'som'\n",
        "\n",
        "    # output_to_bq(som_results, 'clusters_20200739.clusters')\n",
        "    print(\"Upload to BQ completed! üéâ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 28.62229932330481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/minisom.py:511: UserWarning:\n",
            "\n",
            "The topographic error is not defined for a 1-by-1 map.\n",
            "\n",
            "2681it [00:01, 2186.75it/s]\n",
            "1000it [00:00, 2354.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 2 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 24.530185802382075\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2167.18it/s]\n",
            "1000it [00:00, 2260.22it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 3 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 21.59310210230596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2116.74it/s]\n",
            "1000it [00:00, 2286.66it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 4 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 21.062202682086788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2089.48it/s]\n",
            "1000it [00:00, 2179.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 5 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 19.841573891542318\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2130.59it/s]\n",
            "1000it [00:00, 2213.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 6 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 19.49002343512572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2100.44it/s]\n",
            "1000it [00:00, 2031.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 7 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 18.918113461647287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 1656.47it/s]\n",
            "1000it [00:00, 2094.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 8 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " quantization error: 18.75056029192445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2049.31it/s]\n",
            "1000it [00:00, 2136.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 9 clusters....\n",
            " [ 100000 / 100000 ] 100% - 0:00:00 left \n",
            " quantization error: 18.623579866826525\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2681it [00:01, 2037.97it/s]\n",
            "1000it [00:00, 2116.14it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwTqc9CP_DWF",
        "colab_type": "text"
      },
      "source": [
        "### **Train Agglomerative Clusters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTR9D7sm_F6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "bed4f32f-1537-4a36-bf81-918dc7212b36"
      },
      "source": [
        "for i in range(9):\n",
        "    cluster_num = i+1\n",
        "    print(f\"Training {cluster_num} clusters....\")\n",
        "    agglo_cluster = TrainClusters(cluster_type=\"agglo\")\n",
        "    agglo_cluster.fit(norm_df_train, cluster_num=cluster_num)\n",
        "\n",
        "    train_pred = agglo_cluster.predict(norm_df_train)\n",
        "    test_pred = agglo_cluster.predict(norm_df_test)\n",
        "\n",
        "    train_pred['train_test_split'] = \"train\"\n",
        "    test_pred['train_test_split'] = \"test\"\n",
        "    \n",
        "    agglo_results = pd.concat([train_pred[['lcl_id','cluster','train_test_split']], test_pred[['lcl_id','cluster','train_test_split']]])\n",
        "    agglo_results['cluster'] = agglo_results['cluster'].astype(float)\n",
        "    agglo_results['num_clusters'] = cluster_num\n",
        "    agglo_results['cluster_type'] = 'agglo'\n",
        "\n",
        "    output_to_bq(agglo_results, 'clusters_20200739.clusters')\n",
        "    print(\"Upload to BQ completed! üéâ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.84s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 2 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.92s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 3 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.44s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 4 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:04,  4.55s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 5 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.76s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 6 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.39s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 7 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:02,  2.81s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 8 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:06,  6.57s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n",
            "Training 9 clusters....\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.48s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Upload to BQ completed! üéâ\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQMQ6kACRtgv",
        "colab_type": "text"
      },
      "source": [
        "# **3Ô∏è‚É£ Forecasting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hNFBIouR0tx",
        "colab_type": "text"
      },
      "source": [
        "### **Downloading Data from BQ**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iI2320mRx7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_train --use_bqstorage_api\n",
        "SELECT \n",
        "train.lcl_id,\n",
        "train.ts AS ds,\n",
        "train.kwhh AS y,\n",
        "weather.air_temperature\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.train_set` train \n",
        "LEFT JOIN `machine-learning-msc.london_heathrow_hourly_weather_data.london_heathrow_hourly_weather` weather \n",
        "  ON TIMESTAMP_TRUNC(weather.ts, HOUR) = TIMESTAMP_TRUNC(train.ts, hour)\n",
        "  \n",
        "\n",
        "WHERE train.ts >= '2012-11-01' AND train.ts < '2013-03-01'\n",
        "ORDER BY 1,2 ASC"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph4St_mDUcKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc df_test --use_bqstorage_api\n",
        "SELECT \n",
        "train.lcl_id,\n",
        "train.ts AS ds,\n",
        "train.kwhh AS y,\n",
        "weather.air_temperature\n",
        "\n",
        "FROM `machine-learning-msc.forecasting_20200719.test_set` train \n",
        "LEFT JOIN `machine-learning-msc.london_heathrow_hourly_weather_data.london_heathrow_hourly_weather` weather \n",
        "  ON TIMESTAMP_TRUNC(weather.ts, HOUR) = TIMESTAMP_TRUNC(train.ts, hour)\n",
        "  \n",
        "\n",
        "WHERE train.ts >= '2012-11-01' AND train.ts < '2013-03-01'\n",
        "ORDER BY 1,2 ASC"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZQgpcwMUk2b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db65bd5d-7e5f-4ac1-a028-666bbab1f40e"
      },
      "source": [
        "df_train['ds'] = df_train['ds'].dt.tz_localize(None) # remove timezones \n",
        "df_test['ds'] = df_test['ds'].dt.tz_localize(None) # remove timezones \n",
        "\n",
        "print(df_train.shape, df_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15439123, 4) (5758620, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7DdLHFDUmVK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bigquery --project machine-learning-msc clusters --use_bqstorage_api\n",
        "SELECT * FROM `machine-learning-msc.clusters_20200739.clusters`"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7kHACW-Vhzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bb98439d-3a4a-4ac6-9bc8-b39b988d8d45"
      },
      "source": [
        "clusters.head()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lcl_id</th>\n",
              "      <th>cluster</th>\n",
              "      <th>train_test_split</th>\n",
              "      <th>num_clusters</th>\n",
              "      <th>cluster_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MAC000034</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MAC004877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MAC004954</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MAC004970</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MAC005198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>test</td>\n",
              "      <td>8</td>\n",
              "      <td>agglo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      lcl_id  cluster train_test_split  num_clusters cluster_type\n",
              "0  MAC000034      0.0             test             8        agglo\n",
              "1  MAC004877      0.0             test             8        agglo\n",
              "2  MAC004954      0.0             test             8        agglo\n",
              "3  MAC004970      0.0             test             8        agglo\n",
              "4  MAC005198      0.0             test             8        agglo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qJFF57TVnTJ",
        "colab_type": "text"
      },
      "source": [
        "### **Utility Functions..**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbhxIK8nVlTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_clusters(df_train, df_test, test_period=\"2013-02-01\"):\n",
        "    forecast_dict = {}\n",
        "    test_global_fc = pd.DataFrame()\n",
        "    train_global_fc = pd.DataFrame()\n",
        "    clusters = df_train.groupby('cluster').count().index.to_list()\n",
        "    for cluster in clusters:\n",
        "        cluster_dict = {} \n",
        "        print(f\"\\nTraining cluster: {cluster}\") \n",
        "        print(\"---------------------------\")\n",
        "        df_train_cluster = df_train.query(f\"cluster=={cluster}\").copy()\n",
        "        df_test_cluster = df_test.query(f\"cluster=={cluster}\").copy()\n",
        "        model = TrainProphet(test_period)\n",
        "        model.fit(df_train_cluster)\n",
        "        model.evaluate_test_global_mape(df_test_cluster)\n",
        "        cluster_dict['model'] = model \n",
        "        forecast_dict[f'cluster_{cluster}']=cluster_dict\n",
        "        test_global_fc = pd.concat([test_global_fc, model.test_forecast])\n",
        "\n",
        "        train_forecast = df_train[['cluster','ds','y']].copy()\n",
        "        train_forecast['max_households'] = df_train['households_num'].max()\n",
        "        train_forecast = train_forecast.merge(model.forecast[['ds', 'yhat']], left_on='ds', right_on='ds')\n",
        "        train_forecast['y_global'] = train_forecast['y'] * train_forecast['max_households']\n",
        "        train_forecast['yhat_global'] = train_forecast['yhat'] * train_forecast['max_households']\n",
        "        train_global_fc = pd.concat([train_global_fc, train_forecast])\n",
        "\n",
        "    return forecast_dict, test_global_fc, train_global_fc"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEr7g172X0zN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_timeseries(df, clusters_df, cluster_type, num_clusters):\n",
        "    clusters = clusters_df.query(f\"cluster_type=='{cluster_type}' and num_clusters=={num_clusters}\")\n",
        "    out_df = df.merge(clusters[['lcl_id','cluster']], left_on='lcl_id', right_on='lcl_id')\n",
        "    households_num = pd.DataFrame(out_df.groupby('cluster')['lcl_id'].nunique())\n",
        "    households_num.rename(columns={'lcl_id':'households_num'}, inplace=True)\n",
        "\n",
        "    timeseries = out_df.groupby(['cluster','ds']).mean().reset_index()\n",
        "    timeseries = timeseries.merge(households_num, left_on='cluster', right_on='cluster')\n",
        "    return timeseries"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zV6MR_peDBX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cluster_forecast(df_train, df_test, cluster_type, clusters, cluster_list):\n",
        "    results_dict = {}\n",
        "    \n",
        "    for cluster in cluster_list:\n",
        "        cluster_forecast_dict = {}\n",
        "        print(f\"\\n ----------------------------------\")\n",
        "        print(f\"|Total number of clusters: {cluster}...   |\")\n",
        "        print(f\" ----------------------------------\")\n",
        "\n",
        "        train = get_timeseries(df_train, clusters, cluster_type=cluster_type, num_clusters=cluster)\n",
        "        test = get_timeseries(df_test, clusters, cluster_type=cluster_type, num_clusters=cluster)\n",
        "\n",
        "        model_dict, global_test, global_train = train_clusters(train, test)\n",
        "\n",
        "        cluster_forecast_dict['model'] = model_dict\n",
        "        cluster_forecast_dict['global_test'] = global_test\n",
        "        cluster_forecast_dict['global_train'] = global_train \n",
        "\n",
        "        results_dict[f\"num_clusters_{cluster}\"] = cluster_forecast_dict \n",
        "\n",
        "    return results_dict"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kky74E1-V67I",
        "colab_type": "text"
      },
      "source": [
        "### **Training Forecasts**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suydcguUftV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6006e891-df46-43e5-9c67-acef762d4a97"
      },
      "source": [
        "cluster_list = [2,3,4,5,6,7,8]\n",
        "agglo_results = train_cluster_forecast(df_train, df_test, 'agglo', clusters, cluster_list)\n",
        "som_results = train_cluster_forecast(df_train, df_test, 'som', clusters, cluster_list)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " ----------------------------------\n",
            "|Total number of clusters: 2...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.790572916666669\n",
            "Test Mean Absolute Percentage Error: 8.23\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 29.25\n",
            " ----------------------------------\n",
            "|Total number of clusters: 3...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.569873511904763\n",
            "Test Mean Absolute Percentage Error: 64.62\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 156.81\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            " ----------------------------------\n",
            "|Total number of clusters: 4...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.77916666666666\n",
            "Test Mean Absolute Percentage Error: 156.81\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.647232142857149\n",
            "Test Mean Absolute Percentage Error: 52.38\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 72.17\n",
            " ----------------------------------\n",
            "|Total number of clusters: 5...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.647232142857149\n",
            "Test Mean Absolute Percentage Error: 52.38\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 14.201674107142859\n",
            "Test Mean Absolute Percentage Error: 27.939999999999998\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 239.78000000000003\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 27.560000000000002\n",
            " ----------------------------------\n",
            "|Total number of clusters: 6...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 14.201674107142859\n",
            "Test Mean Absolute Percentage Error: 27.939999999999998\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 163.72\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 26.479999999999997\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            " ----------------------------------\n",
            "|Total number of clusters: 7...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.132202380952364\n",
            "Test Mean Absolute Percentage Error: 163.72\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 15.594903273809537\n",
            "Test Mean Absolute Percentage Error: 53.22\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 26.479999999999997\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 1354133157166.448\n",
            "Test Mean Absolute Percentage Error: 100.8\n",
            " ----------------------------------\n",
            "|Total number of clusters: 8...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 79.13171875000015\n",
            "Test Mean Absolute Percentage Error: 57.79\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 11.302418154761911\n",
            "Test Mean Absolute Percentage Error: 60.6\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.447537202380951\n",
            "Test Mean Absolute Percentage Error: 8.110000000000001\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 15.594903273809537\n",
            "Test Mean Absolute Percentage Error: 53.22\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.232142857142842\n",
            "Test Mean Absolute Percentage Error: 71.32\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.893110119047597\n",
            "Test Mean Absolute Percentage Error: 68.35\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 1354133157166.448\n",
            "Test Mean Absolute Percentage Error: 100.8\n",
            "\n",
            "Training cluster: 7.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.861770833333335\n",
            "Test Mean Absolute Percentage Error: 77.81\n",
            " ----------------------------------\n",
            "|Total number of clusters: 2...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.874479166666674\n",
            "Test Mean Absolute Percentage Error: 9.24\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.475699404761915\n",
            "Test Mean Absolute Percentage Error: 13.01\n",
            " ----------------------------------\n",
            "|Total number of clusters: 3...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.89610119047621\n",
            "Test Mean Absolute Percentage Error: 18.01\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.769233630952371\n",
            "Test Mean Absolute Percentage Error: 9.16\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.361011904761908\n",
            "Test Mean Absolute Percentage Error: 8.9\n",
            " ----------------------------------\n",
            "|Total number of clusters: 4...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.408162202380947\n",
            "Test Mean Absolute Percentage Error: 11.74\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.713020833333331\n",
            "Test Mean Absolute Percentage Error: 9.51\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.521272321428574\n",
            "Test Mean Absolute Percentage Error: 9.29\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 67.34281994047618\n",
            "Test Mean Absolute Percentage Error: 55.510000000000005\n",
            " ----------------------------------\n",
            "|Total number of clusters: 5...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.670476190476199\n",
            "Test Mean Absolute Percentage Error: 16.05\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.401599702380938\n",
            "Test Mean Absolute Percentage Error: 10.27\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.524538690476184\n",
            "Test Mean Absolute Percentage Error: 9.78\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.989717261904765\n",
            "Test Mean Absolute Percentage Error: 7.79\n",
            " ----------------------------------\n",
            "|Total number of clusters: 6...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 13.610811011904783\n",
            "Test Mean Absolute Percentage Error: 12.4\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.903065476190479\n",
            "Test Mean Absolute Percentage Error: 10.08\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.114724702380949\n",
            "Test Mean Absolute Percentage Error: 12.6\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.292775297619036\n",
            "Test Mean Absolute Percentage Error: 11.97\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 7.006220238095233\n",
            "Test Mean Absolute Percentage Error: 7.7700000000000005\n",
            " ----------------------------------\n",
            "|Total number of clusters: 7...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.998898809523817\n",
            "Test Mean Absolute Percentage Error: 10.209999999999999\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 17.44555059523811\n",
            "Test Mean Absolute Percentage Error: 14.97\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.553638392857152\n",
            "Test Mean Absolute Percentage Error: 10.96\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.9734226190476\n",
            "Test Mean Absolute Percentage Error: 11.85\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.65594494047619\n",
            "Test Mean Absolute Percentage Error: 14.899999999999999\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.624040178571427\n",
            "Test Mean Absolute Percentage Error: 8.89\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 78.54380208333343\n",
            "Test Mean Absolute Percentage Error: 59.74\n",
            " ----------------------------------\n",
            "|Total number of clusters: 8...   |\n",
            " ----------------------------------\n",
            "\n",
            "Training cluster: 0.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 10.001964285714278\n",
            "Test Mean Absolute Percentage Error: 11.450000000000001\n",
            "\n",
            "Training cluster: 1.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 13.610811011904783\n",
            "Test Mean Absolute Percentage Error: 12.65\n",
            "\n",
            "Training cluster: 2.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 8.352113095238105\n",
            "Test Mean Absolute Percentage Error: 9.8\n",
            "\n",
            "Training cluster: 3.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.225111607142846\n",
            "Test Mean Absolute Percentage Error: 10.35\n",
            "\n",
            "Training cluster: 4.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 9.945193452380959\n",
            "Test Mean Absolute Percentage Error: 13.350000000000001\n",
            "\n",
            "Training cluster: 5.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 6.5765178571428535\n",
            "Test Mean Absolute Percentage Error: 8.64\n",
            "\n",
            "Training cluster: 6.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 104.86796875000003\n",
            "Test Mean Absolute Percentage Error: 65.56\n",
            "\n",
            "Training cluster: 7.0\n",
            "---------------------------\n",
            "Training Mean Absolute Percentage Error: 25.760364583333367\n",
            "Test Mean Absolute Percentage Error: 36.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSnnnoU4lqll",
        "colab_type": "text"
      },
      "source": [
        "### **Evaluate Forecast**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk1MHVS1l24b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5acf934a-ee49-47ae-b9d4-698211699aa3"
      },
      "source": [
        "train_global_results = agglo_results['num_clusters_2']['global_train'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "test_global_results = agglo_results['num_clusters_2']['global_test'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "\n",
        "train_global_mape = np.round(np.mean(np.abs(train_global_results['yhat_global']/train_global_results['y_global']-1)),4)*100\n",
        "test_global_mape = np.round(np.mean(np.abs(test_global_results['yhat_global']/test_global_results['y_global']-1)),4)*100\n",
        "\n",
        "print(train_global_mape, test_global_mape)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.660000000000001 9.180000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GonLw8Vnl2yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate_results(results_dict):\n",
        "    for num_clusters in results_dict.keys():\n",
        "        train_results = results_dict[num_clusters]['global_train'].groupby('ds')[['y_global','yhat_global']].sum()\n",
        "        test_results = results_dict[num_clusters]['global_test'].groupby('ds')[['y_global', 'yhat_global']].sum() \n",
        "\n",
        "        train_global_mape = np.round(np.mean(np.abs(train_results['yhat_global']/train_results['y_global']-1)),4)*100\n",
        "        test_global_mape = np.round(np.mean(np.abs(test_results['yhat_global']/test_results['y_global']-1)),4)*100\n",
        "        results_dict[num_clusters]['train_global_mape'] = train_global_mape\n",
        "        results_dict[num_clusters]['test_global_mape'] = test_global_mape\n",
        "\n",
        "        print(f\"Number of Clusters = {num_clusters}: Train Global MAPE: {train_global_mape}. Test Global MAPE: {test_global_mape}\")"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIAzzlGLl2nO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b56d7b4b-b82a-4968-9b5e-46ad1b9c9b35"
      },
      "source": [
        "evaluate_results(agglo_results)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Clusters = num_clusters_2: Train Global MAPE: 6.660000000000001. Test Global MAPE: 9.180000000000001\n",
            "Number of Clusters = num_clusters_3: Train Global MAPE: 6.569999999999999. Test Global MAPE: 71.78\n",
            "Number of Clusters = num_clusters_4: Train Global MAPE: 12.22. Test Global MAPE: 74.11\n",
            "Number of Clusters = num_clusters_5: Train Global MAPE: 9.27. Test Global MAPE: 77.21000000000001\n",
            "Number of Clusters = num_clusters_6: Train Global MAPE: 8.64. Test Global MAPE: 58.13\n",
            "Number of Clusters = num_clusters_7: Train Global MAPE: 9.06. Test Global MAPE: 57.52\n",
            "Number of Clusters = num_clusters_8: Train Global MAPE: 8.35. Test Global MAPE: 34.02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LulOnGtml12T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "6b8e6837-2a89-4cf6-c724-aff513572a35"
      },
      "source": [
        "evaluate_results(som_results)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Clusters = num_clusters_2: Train Global MAPE: 6.800000000000001. Test Global MAPE: 8.89\n",
            "Number of Clusters = num_clusters_3: Train Global MAPE: 6.77. Test Global MAPE: 8.82\n",
            "Number of Clusters = num_clusters_4: Train Global MAPE: 11.49. Test Global MAPE: 7.7299999999999995\n",
            "Number of Clusters = num_clusters_5: Train Global MAPE: 10.22. Test Global MAPE: 7.55\n",
            "Number of Clusters = num_clusters_6: Train Global MAPE: 8.92. Test Global MAPE: 7.66\n",
            "Number of Clusters = num_clusters_7: Train Global MAPE: 8.67. Test Global MAPE: 7.8100000000000005\n",
            "Number of Clusters = num_clusters_8: Train Global MAPE: 9.48. Test Global MAPE: 7.55\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}