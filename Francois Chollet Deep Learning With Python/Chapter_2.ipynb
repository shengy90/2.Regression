{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Francois Chollet - Deep Learning With Python - Chapter 2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOmFmAFFEdIZjZAhWAJdoYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shengy90/2.Regression/blob/Week1/Francois%20Chollet%20Deep%20Learning%20With%20Python/Chapter_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bln6KOAYI0vf",
        "colab_type": "text"
      },
      "source": [
        "# 1. Super Simple Example of Neural Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HyXgb24D6CC",
        "colab_type": "text"
      },
      "source": [
        "Loading Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj2ZEPo5D7UB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ44bru-ECcd",
        "colab_type": "text"
      },
      "source": [
        "Building a really simple network that comprises of:\n",
        "- 1 `Dense` (aka fully connected) layer with 512 nodes \n",
        "- 1 `Softmax` layer with 10 nodes (to classify 10 digits)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lV_lchwD9tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "model = models.Sequential([\n",
        "                           layers.Dense(512, activation='relu'),\n",
        "                           layers.Dense(10, activation='softmax')\n",
        "                           ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvgOAq4IExx9",
        "colab_type": "text"
      },
      "source": [
        "To make the model ready for training, we still need to pick:\n",
        "- an `optimiser` : mechanism in which the model will update itself based on the training data \n",
        "- a `loss function` : how the model will measure the accuracy on the training data and iterate \n",
        "- a `metric` : to measure accuracy on the test data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnBrjeL_EEof",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    optimizer='rmsprop', # RMSprop - exponentially weighted averages of the gradients \n",
        "    loss='sparse_categorical_crossentropy', # for multiclass classification\n",
        "    metrics=['accuracy'] # simple % of misclassified objects\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upkjiiLSF1g3",
        "colab_type": "text"
      },
      "source": [
        "Before feeding the data into the model, we need to normalise the input data by:\n",
        "- scaling it so that they are between [0,1] to speed up learning by dividing by 255 (number of possible greyscale pixel bits)\n",
        "- reshaping each image into a 28 X 28 array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LahnYodFb1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gxW9AoHGbqE",
        "colab_type": "text"
      },
      "source": [
        "Now let's fit the model with the training data:\n",
        "- 5 epochs (or iterations, or forward pass + backprops)\n",
        "- training 128 images in a single batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Da7dRs0XGETU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkFfEpAEGyjE",
        "colab_type": "text"
      },
      "source": [
        "Let's test the model on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAxKd2HfGhs6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_digits = test_images[0:10] # first 10 images \n",
        "predictions = model.predict(test_digits)\n",
        "\n",
        "print(f\"Prediction for the first image: {predictions[0].argmax()}\")\n",
        "print(f\"Test label for the first image: {test_labels[0]}\")\n",
        "print(f\"Prediction for the fifth image: {predictions[4].argmax()}\")\n",
        "print(f\"Test label for the fifth image: {test_labels[4]}\")\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Average accuracy over the whole test set: {test_acc}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EW781jBIeae",
        "colab_type": "text"
      },
      "source": [
        "Recall that our train set has an accuracy of 98.8%, which is slightly higher than the test set. This discrepancy is what we call 'overfitting' - model has overfit to the train set and doesn't generalise 'well' to data it hasn't seen before. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPu6-nPtKKBP",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Representation in Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQ9dxj6KNeE",
        "colab_type": "text"
      },
      "source": [
        "Data is represented in the form of a `tensor` in Deep Learning. A `tensor` is essentially an array of numbers:\n",
        "- **tensor of rank 0:** a `scaler`, e.g. `1`, `2` or `3` etc.\n",
        "- **tensor of rank 1:** a `vector`, e.g. `[1,2,3,4,5]` etc. In this example, the vector has 5 `dimensions`.\n",
        "- **tensor of rank 2:** a `matrix`, e.g. `[ [1,2,3,4,5], [1,2,3,4,5] ]`. In this example, the matrix is of the dimension 2X5 (2 rows, 5 columns).\n",
        "- **a tensor of rank 3:** e.g. `[ [ [1,2,3,4,5],[1,2,3,4,5] ], [ [2,3,4,5,6],[2,3,4,5,6] ]`. You can essentially think of this as a 'cube' of 2X2X5 numbers (2 axes with each axis having 2 rows and 5 columns).\n",
        "\n",
        "To find out the rank of a tensor, we can use numpy's `ndim` attribute.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36LJqr7pMD6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "t = np.array([\n",
        "              [\n",
        "               [1,2,3,4,5],\n",
        "               [1,2,3,4,5]\n",
        "              ],\n",
        "              [\n",
        "               [2,3,4,5,6],\n",
        "               [2,3,4,5,6]\n",
        "              ]\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a83rPdsQMSTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Tensor t: \\n{t}\")\n",
        "print(f\"Rank of tensor t: {t.ndim}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNvkwJfsNOI7",
        "colab_type": "text"
      },
      "source": [
        "**Key attributes of a tensor:**\n",
        "\n",
        "1. Number of axes (or rank) : can be accessed via `ndim` attribute\n",
        "2. Shape : number of dimensions along each axes; can be accessed via `shape` attribute \n",
        "3. Data type: e.g. floats, integers etc; can be accessed via `dtype` attribute"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMqNli1NO2-8",
        "colab_type": "text"
      },
      "source": [
        "# 3. Engine of Neural Nets : Gradient Based Operations\n",
        "\n",
        "**Neural nets operate by:**\n",
        "1. Start with random initial parameters \n",
        "2. Carry out forward pass : computing $\\hat y$ given $x$\n",
        "3. Carry out backpropagation : computing the derivative of the loss function w.r.t. the weights \n",
        "4. Update weights : $weight_{new} = weight_{old} - \\eta * \\frac{\\delta J}{\\delta weight}$ where J is the loss function\n",
        "5. Do 2. to 4. until loss function stops decreasing (reached minima). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrAHdHTwT5Tg",
        "colab_type": "text"
      },
      "source": [
        "**Representing Forward Pass and Backward Propagation using a computational graph**\n",
        "\n",
        "Let's use linear regression for this example: $\\hat y = w * x + b$\n",
        "\n",
        "And loss function = $(\\hat y-y)^2$.\n",
        "\n",
        "![Computational Graph](https://github.com/shengy90/Deep-Learning-Tutorials/blob/master/misc/forwardbackwards.png?raw=true)\n"
      ]
    }
  ]
}